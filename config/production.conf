admin_port = 9991
admin_http_port = 9990
w3c_header_period = 60000

db {
  username = "$(DB_USERNAME)"
  password = "$(DB_PASSWORD)"
  connection_pool {
    max_wait = 100
    min_evictable_idle_msec = -1
    size_max = 40
    size_min = 40
    test_idle_msec = 1000
    test_on_borrow = false

    timeout {
      initialize = 1000
      open = 50
      pool_size = 10
      queue_size = 10000
    }
  }

  disable {
    error_count = 100
    seconds = 60
  }

  query_timeout_default = 3000
  queries {
    select_source_id_for_update = ["SELECT * FROM ? WHERE source_id = ? FOR UPDATE", 3000]
  }
}

# use a connection pool of 1 when materializing tables.
# (the memoizing connection pools will create a new connection pool because there's no db name.)
materializing_db (inherit="db") {
  connection_pool (inherit="db.connection_pool") {
    size_max = 1
    size_min = 1
  }
}

errors {
  deadlock_retries = 3
}

log {
  filename = "/var/log/flock/production.log"
  level = "info"
  roll = "hourly"
  truncate_stack_traces = 100

  w3c {
    node = "w3c"
    use_parents = false
    filename = "/var/log/flock/w3c.log"
    level = "info"
    roll = "hourly"
  }

  stats {
    node = "stats"
    use_parents = false
    level = "info"
    scribe_category = "flock-stats"
    scribe_server = "localhost"
    scribe_max_packet_size = 100
  }

  bad_jobs {
    node = "bad_jobs"
    use_parents = false
    filename = "/var/log/flock/bad_jobs.log"
    level = "info"
    roll = "never"
  }
}

throttled_log {
  period_msec = 60000
  rate = 10
}

gizzard_services {
  name = "edges"
  min_threads = 200
  shard_server_port = 7917
  job_server_port = 7919
  client_timeout_msec = 100
  idle_timeout_sec = 60
}

edges {
  server_port = 7915
  average_intersection_proportion = 0.1
  intersection_page_size_max = 4000
  aggregate_jobs_page_size = 500
  db_name = "edges"

  w3c = [
    "action-timing",
    "db-timing",
    "connection-pool-release-timing",
    "connection-pool-reserve-timing",
    "database-open-timing",
    "database-close-timing",
    "db-count-query-default",
    "x-db-timing-query-default",
    "kestrel-put-timing",
    "db-count-select",
    "db-count-execute",
    "db-timing-select",
    "db-timing-execute",
    "job-success-count",
    "operation",
    "arguments"
  ]

  nameservers (inherit="db") {
    mapping = "byte_swapper"

    connection_pool {
      max_wait = 100
      min_evictable_idle_msec = -1
      size_max = 1
      size_min = 1
      test_idle_msec = 1000
      test_on_borrow = false

      timeout {
        initialize = 1000
        open = 500
        pool_size = 10
        queue_size = 10000
      }
    }
    query_timeout_default = 15000

    replicas {
      ns1 (inherit="db") {
        hostname = "flockdb001.twitter.com"
        database = "flock_edges_production"
      }

      ns2 (inherit="db") {
        hostname = "flockdb002.twitter.com"
        database = "flock_edges_production"
      }
    }
  }

  future {
    pool_size = 100
    max_pool_size = 100
    keep_alive_time_seconds = 5
    timeout_seconds = 6
  }

  replication {
    future {
      pool_size = 100
      max_pool_size = 100
      keep_alive_time_seconds = 5
      timeout_seconds = 6
    }
  }

  queue {
    path = "/var/spool/kestrel"
    primary {
      job_queue = "edges_jobs"
      error_queue = "edges_errors"
      threads = 64
      error_limit = 100
      replay_interval = 900
    }
    copy {
      job_queue = "copy_jobs"
      error_queue = "copy_errors"
      threads = 24
      error_limit = 1000
      replay_interval = 60
    }
    slow {
      job_queue = "edges_slow_jobs"
      error_queue = "edges_slow_errors"
      threads = 4
      error_limit = 100
      replay_interval = 900
    }
    max_memory_size = 36000000
  }
}
